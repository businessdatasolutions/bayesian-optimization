---
title: "Technical Design Document: Bayesian Optimization Educational Materials"
subtitle: "Mathematical Methodologies and Implementation Specifications"
author: "Witek ten Hove"
date: "2025-01-04"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    html-math-method: katex
    theme: cosmo
    code-fold: true
    code-summary: "Show code"
  pdf:
    toc: true
    number-sections: true
    geometry: margin=1in
    fontsize: 11pt
execute:
  echo: false
  warning: false
---

# Executive Summary

## Project Overview

This Technical Design Document describes the mathematical foundations and implementation details of an educational system for teaching Bayesian Optimization concepts to business professionals in the logistics sector. The system comprises interactive presentations, 3D simulations, and hands-on demonstrations designed to make advanced optimization concepts accessible without requiring deep mathematical background.

## Technical Objectives

1. **Educational Effectiveness**: Implement mathematically rigorous Bayesian Optimization algorithms in an intuitive, visual format
2. **Interactive Learning**: Provide real-time parameter adjustment and visualization of optimization processes
3. **Business Relevance**: Demonstrate practical applications through realistic Distribution Center location optimization scenarios
4. **Performance**: Ensure smooth real-time interaction with educational-grade implementations of complex algorithms

## Target Specifications

- **Audience**: Business professionals with minimal mathematical background
- **Platform**: Web-based (HTML5/JavaScript) with cross-browser compatibility
- **Performance**: Real-time 3D visualization at 30+ FPS on standard business laptops
- **Mathematical Accuracy**: Educational-grade implementations maintaining core algorithm properties

# System Architecture

## Component Overview

The system consists of three primary components:

1. **Static Presentation Layer** (`slides.qmd`)
   - Quarto-generated reveal.js presentation
   - Interactive Plotly visualizations
   - Progressive concept introduction

2. **Interactive 3D Simulator** (`bo-simulator-fast.html`)
   - Three.js-based real-time visualization
   - JavaScript implementation of GP regression
   - User parameter controls and interaction

3. **Mathematical Engine**
   - Gaussian Process regression with RBF kernels
   - Upper Confidence Bound acquisition function
   - Cholesky decomposition for numerical stability

## Technology Stack

- **Frontend**: HTML5, JavaScript ES6+, Three.js, CSS3
- **Mathematical Libraries**: Custom implementations (educational transparency)
- **Visualization**: Three.js (3D), Plotly.js (2D charts)
- **Presentation**: Quarto + reveal.js
- **Performance Optimization**: WebGL rendering, efficient matrix operations

# Mathematical Foundations

## Gaussian Process Regression

### Definition and Setup

A Gaussian Process is a collection of random variables, any finite number of which have a joint Gaussian distribution. For regression, we model an unknown function $f: \mathcal{X} \rightarrow \mathbb{R}$ as:

$$f(\mathbf{x}) \sim \mathcal{GP}(m(\mathbf{x}), k(\mathbf{x}, \mathbf{x}'))$$

where:
- $m(\mathbf{x})$ is the mean function (typically set to 0)
- $k(\mathbf{x}, \mathbf{x}')$ is the covariance function (kernel)

### RBF Kernel Implementation

We use the Radial Basis Function (RBF) kernel, also known as the squared exponential kernel:

$$k(\mathbf{x}_i, \mathbf{x}_j) = \sigma_f^2 \exp\left(-\frac{||\mathbf{x}_i - \mathbf{x}_j||^2}{2\ell^2}\right)$$

where:
- $\sigma_f^2$ is the signal variance (set to 1.0 in implementation)
- $\ell$ is the length scale parameter (set to 5.0 in implementation)
- $||\cdot||^2$ denotes the squared Euclidean distance

### Posterior Distribution

Given training data $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^n$ where $y_i = f(\mathbf{x}_i) + \epsilon_i$ with $\epsilon_i \sim \mathcal{N}(0, \sigma_n^2)$, the posterior distribution at test point $\mathbf{x}_*$ is:

$$f(\mathbf{x}_*) | \mathcal{D} \sim \mathcal{N}(\mu(\mathbf{x}_*), \sigma^2(\mathbf{x}_*))$$

where the predictive mean and variance are:

$$\mu(\mathbf{x}_*) = \mathbf{k}_*^T (\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{y}$$

$$\sigma^2(\mathbf{x}_*) = k(\mathbf{x}_*, \mathbf{x}_*) - \mathbf{k}_*^T (\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{k}_*$$

where:
- $\mathbf{K}$ is the $n \times n$ kernel matrix with $K_{ij} = k(\mathbf{x}_i, \mathbf{x}_j)$
- $\mathbf{k}_*$ is the $n \times 1$ vector with $[\mathbf{k}_*]_i = k(\mathbf{x}_i, \mathbf{x}_*)$
- $\mathbf{y}$ is the vector of observed function values
- $\sigma_n^2$ is the noise variance

### Numerical Stability via Cholesky Decomposition

To avoid numerical instability from matrix inversion, we use Cholesky decomposition. Given $\mathbf{L}\mathbf{L}^T = \mathbf{K} + \sigma_n^2 \mathbf{I}$, we solve:

$$\mathbf{L}\boldsymbol{\alpha} = \mathbf{y} \quad \text{and} \quad \mathbf{L}\mathbf{v} = \mathbf{k}_*$$

Then:
$$\mu(\mathbf{x}_*) = \mathbf{v}^T \boldsymbol{\alpha}$$
$$\sigma^2(\mathbf{x}_*) = k(\mathbf{x}_*, \mathbf{x}_*) - \mathbf{v}^T \mathbf{v}$$

## Acquisition Functions

### Upper Confidence Bound (UCB)

The UCB acquisition function balances exploitation and exploration:

$$\alpha_{\text{UCB}}(\mathbf{x}) = \mu(\mathbf{x}) + \beta \sigma(\mathbf{x})$$

For minimization problems (as in our DC location scenario), we use:

$$\alpha_{\text{UCB}}(\mathbf{x}) = -(\mu(\mathbf{x}) - \beta \sigma(\mathbf{x}))$$

where:
- $\mu(\mathbf{x})$ is the GP posterior mean
- $\sigma(\mathbf{x})$ is the GP posterior standard deviation
- $\beta > 0$ is the exploration parameter (user-adjustable in simulator)

### Parameter $\beta$ Interpretation

- **Low $\beta$ (exploitation)**: Focus on areas with low predicted mean
- **High $\beta$ (exploration)**: Prioritize areas with high uncertainty
- **Typical range**: $\beta \in [0.1, 10]$ in educational settings

## Objective Function Design

### Distribution Center Cost Model

The true objective function combines multiple cost components:

$$f(\mathbf{x}) = C_{\text{transport}}(\mathbf{x}) + C_{\text{terrain}}(\mathbf{x}) + C_{\text{optimal}}(\mathbf{x})$$

#### Transportation Cost
$$C_{\text{transport}}(\mathbf{x}) = \sum_{i=1}^{N} ||\mathbf{x} - \mathbf{c}_i||_2$$

where $\mathbf{c}_i$ are customer locations and $N = 30$.

#### Terrain Cost (High-cost zones)
$$C_{\text{terrain}}(\mathbf{x}) = 200 \exp\left(-0.01 ||\mathbf{x} - \mathbf{p}_1||^2\right) + 300 \exp\left(-0.02 ||\mathbf{x} - \mathbf{p}_2||^2\right)$$

where $\mathbf{p}_1$ and $\mathbf{p}_2$ are positions of terrain obstacles.

#### Optimal Zone Benefit
$$C_{\text{optimal}}(\mathbf{x}) = -500 \exp\left(-0.03 ||\mathbf{x} - \mathbf{o}||^2\right)$$

where $\mathbf{o}$ is the location of a special low-cost zone, creating a non-obvious optimum.

# Implementation Details

## Gaussian Process Implementation in bo-simulator-fast.html

### Core SimpleGP Class Structure

The actual implementation in `bo-simulator-fast.html` uses a comprehensive `SimpleGP` class that maintains the complete GP state:

```javascript
class SimpleGP {
    constructor(kernelScale = 5.0) {
        this.X = null;           // Training inputs
        this.y = null;           // Training outputs  
        this.L = null;           // Cholesky factor
        this.alpha = null;       // Precomputed solution vector
        this.kernelScale = kernelScale;
    }
    
    kernel(x1, x2) {
        const sqdist = x1.reduce((acc, val, i) => 
            acc + Math.pow(val - x2[i], 2), 0);
        return Math.exp(-0.5 / this.kernelScale ** 2 * sqdist);
    }
}
```

### RBF Kernel Implementation Details

The simulator implements the **Radial Basis Function (RBF) kernel** with specific parameter choices:

- **Length Scale (ℓ)**: Fixed at `kernelScale = 5.0`
- **Signal Variance**: Implicitly set to 1.0 (no σ²ᶠ multiplier)
- **Input Handling**: Optimized for 2D points `[x, z]` representing DC locations
- **Smoothness Assumption**: RBF kernel assumes infinitely differentiable functions

### Advanced Numerical Stability through Cholesky Decomposition

The implementation prioritizes numerical stability using Cholesky decomposition instead of direct matrix inversion:

```javascript
fit(X, y) {
    this.X = X;
    this.y = y;
    const n = X.length;
    const K = Array(n).fill(0).map(() => Array(n).fill(0));
    
    // Build kernel matrix with jitter
    for (let i = 0; i < n; i++) {
        for (let j = 0; j < n; j++) {
            K[i][j] = this.kernel(X[i], X[j]);
        }
        K[i][i] += 1e-5; // Numerical stability jitter
    }
    
    try {
        this.L = this.cholesky(K);
        this.alpha = this.solve(K, y);
    } catch(e) {
        console.error("Cholesky decomposition failed. GP might be unstable.", e);
        this.alpha = null; // Graceful degradation
    }
}
```

**Why Cholesky Decomposition?**
- **Numerical Stability**: Avoids ill-conditioning issues with direct matrix inversion
- **Computational Efficiency**: O(n³/3) operations vs O(n³) for full inversion
- **Memory Efficiency**: Stores only lower triangular matrix L
- **Error Detection**: Fails gracefully when kernel matrix becomes singular

### GP Posterior Prediction Implementation

The prediction method implements the full GP posterior with variance computation:

```javascript
predict(X_test) {
    if (!this.alpha) return { 
        mean: Array(X_test.length).fill(0), 
        std: Array(X_test.length).fill(1) 
    };

    const means = [];
    const stds = [];
    
    for (const x_star of X_test) {
        // Compute k* vector: k*[i] = k(x_i, x*)
        const k_star = this.X.map(xi => this.kernel(x_star, xi));
        
        // Predictive mean: μ* = k*ᵀ α
        const mean = k_star.reduce((acc, val, i) => acc + val * this.alpha[i], 0);
        
        // Predictive variance: σ²* = k** - vᵀv where Lv = k*
        const v = this.solveLowerTriangular(this.L, k_star);
        const variance = this.kernel(x_star, x_star) - 
                        v.reduce((acc, val) => acc + val*val, 0);
        
        means.push(mean);
        stds.push(Math.sqrt(Math.max(0, variance)));
    }
    return { mean: means, std: stds };
}
```

### Optimized Linear Algebra Routines

The implementation includes efficient triangular system solvers:

```javascript
solveLowerTriangular(L, b) {
    const n = L.length;
    const x = Array(n).fill(0);
    for (let i = 0; i < n; i++) {
        let sum = 0;
        for (let j = 0; j < i; j++) {
            sum += L[i][j] * x[j];
        }
        x[i] = (b[i] - sum) / L[i][i];
    }
    return x;
}

solveUpperTriangular(U, b) {
    const n = U.length;
    const x = Array(n).fill(0);
    for (let i = n - 1; i >= 0; i--) {
        let sum = 0;
        for (let j = i + 1; j < n; j++) {
            sum += U[i][j] * x[j];
        }
        x[i] = (b[i] - sum) / U[i][i];
    }
    return x;
}
```

## 3D Visualization Pipeline

### Surface Generation

The 3D surfaces are generated using Three.js PlaneGeometry with function evaluation at vertices:

1. **Grid Generation**: Create $n \times n$ grid of points in domain $[-25, 25] \times [-25, 25]$
2. **Function Evaluation**: Evaluate GP mean/std or acquisition function at each grid point
3. **Vertex Coloring**: Map uncertainty values to color gradients
4. **Normal Computation**: Calculate vertex normals for lighting

### Real-time Updates

Surface updates are optimized for real-time interaction:

- **Lazy Evaluation**: Only recompute changed surfaces
- **Vertex Buffer Updates**: Direct modification of GPU vertex buffers
- **Render-on-Change**: Triggered rendering instead of continuous loops

## Performance Optimizations

The `bo-simulator-fast.html` implementation includes several optimizations for real-time interactive performance:

### Real-Time Rendering Optimizations
```javascript
// Adaptive grid resolution based on data points
const gridSize = Math.min(50, Math.max(20, Math.floor(Math.sqrt(dataPoints.length * 10))));

// Quality control for Three.js rendering
renderer.shadowMap.enabled = true;
renderer.shadowMap.type = THREE.PCFSoftShadowMap;
renderer.antialias = true;
```

### Mathematical Optimizations
1. **Cholesky Decomposition Cache**: The `SimpleGP.fit()` method caches the Cholesky factor `L` to avoid recomputation:
   ```javascript
   this.L = this.choleskyDecomposition(K_noise);
   this.alpha = this.forwardBackwardSubstitution(this.L, this.y);
   ```

2. **Vectorized Grid Evaluation**: UCB acquisition function evaluated on entire grid simultaneously:
   ```javascript
   for (let i = 0; i < gridX.length; i++) {
       const ucb = -(prediction.mean[i] - boState.beta * prediction.std[i]);
       acquisitionValues.push(ucb);
   }
   ```

3. **Distance-Based Constraints**: Minimum distance enforcement prevents clustering:
   ```javascript
   const minDistance = 0.15; // Prevent points too close together
   const tooClose = boState.dataPoints.some(point => 
       Math.sqrt((x - point.x)**2 + (y - point.y)**2) < minDistance
   );
   ```

### Memory Management
- **Selective Recomputation**: Only GP model refitted when new data added, visualizations updated incrementally
- **Grid Caching**: Acquisition surface computed once per iteration, reused for visualization updates

### Computational Complexity
- **GP Training**: $O(n^3)$ for Cholesky decomposition, $O(n^2)$ storage
- **GP Prediction**: $O(n)$ per prediction after preprocessing  
- **Surface Updates**: $O(m^2)$ where $m$ is grid resolution (default: 25)

## Complete Objective Function Implementation

The `bo-simulator-fast.html` implements a three-component cost model for distribution center location optimization:

### Mathematical Formulation
```javascript
function trueObjective(x, y) {
    // Customer distribution centers (simulated locations)
    const customers = [
        {x: -15, y: 8, demand: 120},
        {x: 12, y: -5, demand: 80},
        {x: -8, y: -12, demand: 100},
        {x: 20, y: 15, demand: 90},
        {x: -20, y: -8, demand: 70}
    ];
    
    // Three-component cost model
    let totalCost = 0;
    
    // 1. Transportation costs (distance-based)
    customers.forEach(customer => {
        const distance = Math.sqrt((x - customer.x)**2 + (y - customer.y)**2);
        totalCost += distance * customer.demand * 0.8; // $0.8 per unit-mile
    });
    
    // 2. Land acquisition costs (location-dependent)
    const landCost = 1000 + 50 * (x**2 + y**2) / 100; // Higher cost away from center
    totalCost += landCost;
    
    // 3. Operational efficiency penalty (zoning constraints)
    if (x > 15 && y > 10) totalCost *= 1.4; // Industrial zoning penalty
    if (x < -18 && y < -10) totalCost *= 1.3; // Environmental restrictions
    
    return totalCost;
}
```

### Hidden Optimal Zone
The objective function includes a concealed optimal region that challenges traditional intuition:

```javascript
// Hidden bonus zone (not obvious from customer locations)
if (x >= -5 && x <= 2 && y >= -3 && y <= 4) {
    totalCost *= 0.7; // 30% cost reduction due to tax incentives
}
```

This design demonstrates why Bayesian Optimization excels: the global optimum lies away from the intuitive center-of-mass location, requiring intelligent exploration to discover.

### Business Interpretation
- **Transportation Component**: Reflects real logistics where distance drives delivery costs
- **Land Cost Component**: Models urban vs suburban real estate pricing
- **Regulatory Component**: Captures zoning laws and environmental regulations
- **Hidden Incentives**: Represents tax breaks or special economic zones

# Educational Design Principles

## Progressive Complexity

The educational sequence follows Bloom's taxonomy:

1. **Remember**: Basic concepts (black-box, expensive evaluation)
2. **Understand**: Component roles (predictor, decision maker)
3. **Apply**: Interactive parameter adjustment
4. **Analyze**: Compare different strategies (exploration vs exploitation)
5. **Evaluate**: Assess performance in realistic scenarios
6. **Create**: Experiment with custom parameter settings

## Mathematical Transparency

While maintaining educational accessibility:

- **Simplified Notation**: Use intuitive variable names in interface
- **Visual Correspondence**: Direct mapping between math concepts and visual elements
- **Interactive Exploration**: Parameter sliders with immediate visual feedback

## Visual-Mathematical Correspondence

The `bo-simulator-fast.html` creates direct mappings between abstract mathematical concepts and 3D visual elements:

### Gaussian Process Visualization
```javascript
// Mean function surface (blue-green gradient)
meanGeometry.vertices.forEach((vertex, i) => {
    vertex.z = prediction.mean[i];
    const normalizedMean = (prediction.mean[i] - minMean) / (maxMean - minMean);
    colors[i] = new THREE.Color().setHSL(0.5 + normalizedMean * 0.2, 0.8, 0.6);
});
```

**Mathematical Concept**: $\mu(\mathbf{x}) = \mathbf{k}(\mathbf{x})^T(\mathbf{K} + \sigma^2\mathbf{I})^{-1}\mathbf{y}$
**Visual Representation**: 3D surface height represents predicted cost, color gradient shows confidence

### Uncertainty Quantification
```javascript
// Standard deviation represented as surface transparency
const uncertainty = prediction.std[i];
const alpha = Math.max(0.3, Math.min(1.0, uncertainty / maxStd));
material.opacity = alpha;
```

**Mathematical Concept**: $\sigma^2(\mathbf{x}) = k(\mathbf{x}, \mathbf{x}) - \mathbf{k}(\mathbf{x})^T(\mathbf{K} + \sigma^2\mathbf{I})^{-1}\mathbf{k}(\mathbf{x})$
**Visual Representation**: Surface transparency indicates prediction uncertainty

### Acquisition Function Visualization
```javascript
// UCB surface (red intensity shows exploration priority)
const ucbValue = -(prediction.mean[i] - beta * prediction.std[i]);
const redIntensity = Math.max(0, Math.min(1, ucbValue / maxUCB));
acquisitionColors[i] = new THREE.Color(redIntensity, 0, 0);
```

**Mathematical Concept**: $\alpha_{UCB}(\mathbf{x}) = \mu(\mathbf{x}) - \beta\sigma(\mathbf{x})$ (for minimization)
**Visual Representation**: Red intensity indicates where algorithm should sample next

### Data Point Integration
```javascript
// Observed points as 3D spheres with vertical lines to surface
dataPoints.forEach(point => {
    const sphere = new THREE.Mesh(sphereGeometry, sphereMaterial);
    sphere.position.set(point.x, point.y, point.value);
    
    // Connection line shows true vs predicted values
    const lineGeometry = new THREE.BufferGeometry().setFromPoints([
        new THREE.Vector3(point.x, point.y, 0),
        new THREE.Vector3(point.x, point.y, point.value)
    ]);
});
```

**Mathematical Concept**: Training data $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^n$
**Visual Representation**: Gold spheres show evaluated locations, vertical lines connect to cost surface

### Interactive Parameter Control
```javascript
// Beta slider directly controls exploration-exploitation balance
betaSlider.addEventListener('input', (e) => {
    boState.beta = parseFloat(e.target.value);
    updateAcquisitionSurface(); // Immediate visual feedback
});
```

**Mathematical Impact**: Higher $\beta$ increases $\sigma(\mathbf{x})$ weight, promoting exploration
**Visual Feedback**: Real-time red surface changes as user adjusts slider

## Business Context Integration

Every mathematical concept is grounded in business reality:

- **Cost Functions**: Realistic transportation and operational costs
- **Decision Scenarios**: Authentic logistics optimization challenges
- **Performance Metrics**: Business-relevant KPIs (number of studies, cost savings)

# Testing and Validation

## Mathematical Correctness

### GP Regression Validation
- **Known Function Tests**: Verify GP convergence on analytical functions
- **Noise Handling**: Validate posterior uncertainty with controlled noise levels
- **Kernel Properties**: Ensure RBF kernel maintains positive definiteness

### Optimization Performance
- **Convergence Testing**: Verify convergence to global optimum within expected iterations
- **Exploration-Exploitation Balance**: Validate UCB parameter effects
- **Comparative Analysis**: Compare with random sampling baseline

## Numerical Stability

### Matrix Operations
- **Condition Number Monitoring**: Track kernel matrix conditioning
- **Cholesky Stability**: Verify decomposition accuracy with residual analysis
- **Precision Testing**: Validate accuracy across different floating-point precisions

## User Experience Testing

### Performance Benchmarks
- **Frame Rate**: Maintain >30 FPS on target hardware
- **Response Time**: <100ms for parameter adjustments
- **Memory Usage**: <500MB total memory footprint

### Educational Effectiveness
- **Learning Objective Assessment**: Pre/post understanding measurements
- **Interaction Analytics**: Track user engagement with different components
- **Cognitive Load**: Ensure information density remains manageable

# Deployment and Maintenance

## Browser Compatibility

### Target Browsers
- Chrome/Chromium 90+
- Firefox 88+
- Safari 14+
- Edge 90+

### Feature Detection
```javascript
// WebGL support verification
const canvas = document.createElement('canvas');
const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');
if (!gl) {
    // Fallback to 2D visualization
}
```

## Performance Monitoring

### Client-side Metrics
- **Frame Rate**: Monitor WebGL rendering performance
- **Memory Usage**: Track JavaScript heap size
- **Load Times**: Measure initial page load and resource loading

### Error Handling
- **Matrix Singularity**: Graceful degradation when GP becomes unstable
- **Browser Limits**: Detect and adapt to device capabilities
- **Network Issues**: Offline capability for core functionality

# Appendices

## A. Mathematical Proofs

### A.1 GP Posterior Derivation

Given the GP prior $f(\mathbf{x}) \sim \mathcal{GP}(0, k(\mathbf{x}, \mathbf{x}'))$ and likelihood $y_i = f(\mathbf{x}_i) + \epsilon_i$ where $\epsilon_i \sim \mathcal{N}(0, \sigma_n^2)$, the joint distribution is:

$$\begin{pmatrix} \mathbf{y} \\ f_* \end{pmatrix} \sim \mathcal{N}\left(\mathbf{0}, \begin{pmatrix} \mathbf{K} + \sigma_n^2\mathbf{I} & \mathbf{k}_* \\ \mathbf{k}_*^T & k_{**} \end{pmatrix}\right)$$

Using the conditional distribution formula for multivariate Gaussians:

$$f_* | \mathbf{y} \sim \mathcal{N}(\mathbf{k}_*^T(\mathbf{K} + \sigma_n^2\mathbf{I})^{-1}\mathbf{y}, k_{**} - \mathbf{k}_*^T(\mathbf{K} + \sigma_n^2\mathbf{I})^{-1}\mathbf{k}_*)$$

## B. Algorithm Pseudocode

### B.1 Bayesian Optimization Loop

```
Algorithm: Bayesian Optimization for DC Location

Input: Domain D, Objective f, Initial points X₀, Budget T
Output: Optimal location x*

1. Initialize GP with X₀ and y₀ = f(X₀)
2. For t = 1 to T:
   a. Fit GP to current data (X_{t-1}, y_{t-1})
   b. Compute acquisition function α(x) over domain D
   c. Find x_t = argmax α(x)
   d. Evaluate y_t = f(x_t)
   e. Augment data: X_t = X_{t-1} ∪ {x_t}, y_t = y_{t-1} ∪ {y_t}
3. Return x* = argmin y_t over all evaluated points
```

### B.2 GP Prediction Algorithm

```
Algorithm: GP Prediction with Cholesky Decomposition

Input: Training data (X, y), Test point x*, Kernel k, Noise σ²
Output: Predictive mean μ*, variance σ²*

1. Compute kernel matrix K with K_ij = k(x_i, x_j)
2. Add noise: K = K + σ²I
3. Compute Cholesky decomposition: L = chol(K)
4. Solve Lα = y for α
5. Compute k* with [k*]_i = k(x_i, x*)
6. Solve Lv = k* for v
7. Return μ* = v^T α, σ²* = k(x*, x*) - v^T v
```

## C. References and Further Reading

1. Rasmussen, C. E., & Williams, C. K. (2006). *Gaussian processes for machine learning*. MIT Press.

2. Srinivas, N., Krause, A., Kakade, S. M., & Seeger, M. (2009). Gaussian process optimization in the bandit setting: No regret and experimental design. *ICML*.

3. Shahriari, B., Swersky, K., Wang, Z., Adams, R. P., & de Freitas, N. (2015). Taking the human out of the loop: A review of Bayesian optimization. *Proceedings of the IEEE*.

4. Frazier, P. I. (2018). A tutorial on Bayesian optimization. *arXiv preprint arXiv:1807.02811*.

---

**Document Version**: 1.0  
**Last Updated**: January 4, 2025  
**Classification**: Technical Documentation  
**Distribution**: Educational Use
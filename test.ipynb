{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Decisions for Logistics: An Introduction to Bayesian Optimization\n",
    "---\n",
    "**Target Audience:** Medior Business Managers in the Logistics Sector (untrained in Math and Statistics)  \n",
    "**Duration:** 20 Minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Your \"Smart Logistics\" Goals\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "\n",
    "* **üéØ Identify Opportunities for Smarter Testing:** Spot areas in your operations where traditional 'trial and error' is too slow or expensive.\n",
    "\n",
    "* **üöÄ Understand How to Get Better Results, Faster:** Grasp how Bayesian Optimization can find the best solutions (e.g., for a new routing algorithm or warehouse layout) using fewer, smarter tests.\n",
    "\n",
    "* **üó£Ô∏è Speak the Language of Intelligent Optimisation:** Understand the core ideas behind 'smart predictors' and 'smart decision-makers' to have more informed conversations with your data science teams.\n",
    "\n",
    "* **‚öñÔ∏è Recognise the Power of Balanced Strategy:** Understand why a balanced approach of 'checking new things' (exploration) and 'fine-tuning current bests' (exploitation) is crucial for innovation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Program Outline\n",
    "\n",
    "#### Introduction (2 minutes)\n",
    "* **The Challenge in Logistics:** You face complex decisions every day ‚Äì optimising routes, warehouse layouts, or inventory strategies. Finding the \"best\" solution often involves a lot of trial-and-error.\n",
    "* **The Problem with Traditional Approaches:** In logistics, each 'trial' can be incredibly expensive in time, fuel, and labour. You can't just run millions of tests.\n",
    "* **Introducing Bayesian Optimization (BO):** Imagine an intelligent assistant that learns from every test you run and then suggests the *absolute smartest next test* to get you to the best solution as quickly as possible. That‚Äôs BO in a nutshell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Problem: Expensive \"Black-Box\" Optimisation (4 minutes)\n",
    "\n",
    "**What is a \"Black-Box\"?**\n",
    "\n",
    "Think of a new route planning software. You enter settings (like vehicle capacity or delivery windows), and it gives you an efficiency score. You can't see the complex code inside‚Äîit‚Äôs a \"black box.\" You only know the inputs and the outputs.\n",
    "\n",
    "**Why is finding the best setting \"Expensive\"?**\n",
    "\n",
    "Evaluating a new logistics strategy involves real-world tests or complex simulations that cost:\n",
    "\n",
    "* **Time:** A pilot test for a new routing algorithm can take weeks.\n",
    "* **Money:** Fuel, driver wages, and potential disruptions.\n",
    "* **Resources:** Vehicles, staff, and computing power.\n",
    "\n",
    "**The Dilemma:** You want the best result, but testing every possible combination is impossible. Random guesses are inefficient. We need a smarter strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bayesian Optimization: The Smart Strategy (7 minutes)\n",
    "\n",
    "BO uses two components in a cycle: a **\"Smart Predictor\"** and a **\"Smart Decision Maker\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. The \"Smart Predictor\" (Surrogate Model)\n",
    "\n",
    "This is a statistical model that learns from your test results to \"guess\" what the black-box function looks like everywhere else. It's like an experienced manager who can predict how a new route might perform based on their knowledge of similar ones.\n",
    "\n",
    "Crucially, it also tells you **how confident** it is in its prediction.\n",
    "\n",
    "* **The Solid Line:** The model's \"best guess.\"\n",
    "* **The Shaded Area:** The uncertainty. A wide area means \"we don't know much here.\" A narrow one means \"we're pretty sure.\"\n",
    "\n",
    "**üëá Interactive Demo:** Click on the graph below to add test results. See how the \"Smart Predictor\" updates its belief and reduces uncertainty with each click."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:450: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8438a951a60f46099621a3558735f0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'red', 'dash': 'dash'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'True Efficiency (Unknown)',\n",
       "              'type': 'scatter',\n",
       "              'uid': '066c4920-258d-4a47-ad72-400c2eedd982',\n",
       "              'x': {'bdata': ('AAAAAAAAAACBhJ9ciLq5P4GEn1yIus' ... '+KzDNAfGCjd0XmM0AAAAAAAAA0QA=='),\n",
       "                    'dtype': 'f8'},\n",
       "              'xaxis': 'x',\n",
       "              'y': {'bdata': ('AAAAAAAAOUD8pI5LcYM9QMaKDfBs/E' ... '8jbzlAaTXK4Cs0OUAAAAAAAAA5QA=='),\n",
       "                    'dtype': 'f8'},\n",
       "              'yaxis': 'y'},\n",
       "             {'marker': {'color': 'red', 'size': 12, 'symbol': 'x'},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Test Results',\n",
       "              'type': 'scatter',\n",
       "              'uid': '49a7985a-8bf3-49ba-aa35-5bd26396b934',\n",
       "              'x': {'bdata': 'AAAAAAAAAEAAAAAAAAAyQA==', 'dtype': 'f8'},\n",
       "              'xaxis': 'x',\n",
       "              'y': {'bdata': 'v7l7XgTtTkAJFEHrgPw6QA==', 'dtype': 'f8'},\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'rgba(0,100,80,0.2)'},\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '317526a8-293a-4414-83fc-28452cf59648',\n",
       "              'x': {'bdata': ('AAAAAAAAAACBhJ9ciLq5P4GEn1yIus' ... '+KzDNAfGCjd0XmM0AAAAAAAAA0QA=='),\n",
       "                    'dtype': 'f8'},\n",
       "              'xaxis': 'x',\n",
       "              'y': {'bdata': ('c3v7UhoMUUCzg2Meg/hQQEmCd5LS5F' ... '6egTtA4EcZhu2PO0BcQ9Ws7J47QA=='),\n",
       "                    'dtype': 'f8'},\n",
       "              'yaxis': 'y'},\n",
       "             {'fill': 'tonexty',\n",
       "              'fillcolor': 'rgba(0,100,80,0.2)',\n",
       "              'line': {'color': 'rgba(0,100,80,0.2)'},\n",
       "              'name': 'Uncertainty',\n",
       "              'type': 'scatter',\n",
       "              'uid': '666b5f0d-83d8-4538-8b69-71bab0d0b8ee',\n",
       "              'x': {'bdata': ('AAAAAAAAAACBhJ9ciLq5P4GEn1yIus' ... '+KzDNAfGCjd0XmM0AAAAAAAAA0QA=='),\n",
       "                    'dtype': 'f8'},\n",
       "              'xaxis': 'x',\n",
       "              'y': {'bdata': ('wD2m/B0gTECBmLWTEEpMQJiDhGJrc0' ... 'oq1TBA1Gn2MwJCMECooWe0fl0vQA=='),\n",
       "                    'dtype': 'f8'},\n",
       "              'yaxis': 'y'},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': '\"Smart Predictor\" Guess',\n",
       "              'type': 'scatter',\n",
       "              'uid': '5fe50d33-ed09-459f-aac0-1d2c4b25223f',\n",
       "              'x': {'bdata': ('AAAAAAAAAACBhJ9ciLq5P4GEn1yIus' ... '+KzDNAfGCjd0XmM0AAAAAAAAA0QA=='),\n",
       "                    'dtype': 'f8'},\n",
       "              'xaxis': 'x',\n",
       "              'y': {'bdata': ('U5pOUSkcT0DzTz5oix1PQBXEuUOIHk' ... 'xkKzZA2tgH3ffoNUAYioQD1qY1QA=='),\n",
       "                    'dtype': 'f8'},\n",
       "              'yaxis': 'y'}],\n",
       "    'layout': {'legend': {'orientation': 'h', 'x': 1, 'xanchor': 'right', 'y': 1.02, 'yanchor': 'bottom'},\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Interactive Demo: The \"Smart Predictor\"'},\n",
       "               'xaxis': {'anchor': 'y', 'domain': [0.0, 1.0], 'title': {'text': 'Route Configuration Parameter'}},\n",
       "               'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Logistics Efficiency Score'}}}\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# 1. Define the true \"black-box\" function (for demonstration purposes)\n",
    "# In a real scenario, we would not know this function.\n",
    "def black_box_function(x):\n",
    "    \"\"\"A complex function representing logistics efficiency vs. a parameter.\"\"\"\n",
    "    return np.sin(0.9 * x) * np.sinc(x * 0.2) * 50 + 25\n",
    "\n",
    "# 2. Setup for the plot\n",
    "x_range = np.linspace(0, 20, 200).reshape(-1, 1)\n",
    "y_true = black_box_function(x_range)\n",
    "\n",
    "# Initial sample points\n",
    "X_samples = np.array([[2.0], [18.0]])\n",
    "y_samples = black_box_function(X_samples)\n",
    "\n",
    "# Kernel for the Gaussian Process\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "\n",
    "# Create the figure\n",
    "fig = go.FigureWidget(make_subplots(rows=1, cols=1))\n",
    "fig.add_trace(go.Scatter(x=x_range.ravel(), y=y_true.ravel(), mode='lines', \n",
    "                         line=dict(color='red', dash='dash'), name='True Efficiency (Unknown)'), row=1, col=1)\n",
    "\n",
    "# Add initial components to the plot\n",
    "fig.add_trace(go.Scatter(x=X_samples.ravel(), y=y_samples.ravel(), mode='markers', \n",
    "                         marker=dict(color='red', size=12, symbol='x'), name='Test Results'), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[], y=[], line=dict(color='rgba(0,100,80,0.2)'), showlegend=False), row=1, col=1) # Upper bound\n",
    "fig.add_trace(go.Scatter(x=[], y=[], line=dict(color='rgba(0,100,80,0.2)'), fill='tonexty', fillcolor='rgba(0,100,80,0.2)', name='Uncertainty'), row=1, col=1) # Lower bound\n",
    "fig.add_trace(go.Scatter(x=[], y=[], mode='lines', line=dict(color='green', width=3), name='\"Smart Predictor\" Guess'), row=1, col=1)\n",
    "\n",
    "def update_gp(X, y):\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, random_state=0)\n",
    "    gp.fit(X, y)\n",
    "    y_pred, sigma = gp.predict(x_range, return_std=True)\n",
    "    return y_pred.ravel(), sigma.ravel()\n",
    "\n",
    "def update_plot(X, y):\n",
    "    y_pred, sigma = update_gp(X, y)\n",
    "    \n",
    "    # Update GP prediction and uncertainty\n",
    "    fig.data[2].x = x_range.ravel()\n",
    "    fig.data[2].y = y_pred + 1.96 * sigma\n",
    "    fig.data[3].x = x_range.ravel()\n",
    "    fig.data[3].y = y_pred - 1.96 * sigma\n",
    "    fig.data[4].x = x_range.ravel()\n",
    "    fig.data[4].y = y_pred\n",
    "    \n",
    "    # Update sample points\n",
    "    fig.data[1].x = X.ravel()\n",
    "    fig.data[1].y = y.ravel()\n",
    "    \n",
    "    \n",
    "# Function to handle clicks\n",
    "def on_click(trace, points, state):\n",
    "    if points.point_inds:\n",
    "        # Get click location\n",
    "        x_click = points.xs[0]\n",
    "        y_click = black_box_function(np.array([[x_click]]))\n",
    "        \n",
    "        # Update global samples\n",
    "        global X_samples, y_samples\n",
    "        X_samples = np.vstack([X_samples, [x_click]])\n",
    "        y_samples = np.vstack([y_samples, y_click])\n",
    "        \n",
    "        # Redraw the plot\n",
    "        update_plot(X_samples, y_samples)\n",
    "\n",
    "# Attach click handler to the first trace (the invisible background)\n",
    "fig.data[0].on_click(on_click)\n",
    "\n",
    "# Initial plot render\n",
    "update_plot(X_samples, y_samples)\n",
    "\n",
    "fig.update_layout(title='Interactive Demo: The \"Smart Predictor\"',\n",
    "                  xaxis_title='Route Configuration Parameter',\n",
    "                  yaxis_title='Logistics Efficiency Score',\n",
    "                  legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. The \"Smart Decision Maker\" (Acquisition Function)\n",
    "\n",
    "This component takes the predictor's output (guess + uncertainty) and decides **where you should run your next expensive test.**\n",
    "\n",
    "It performs a balancing act between:\n",
    "\n",
    "* **üîµ Exploitation:** \"Let's test in an area that the predictor thinks is *already good* to fine-tune our best solution.\"\n",
    "* **üü¢ Exploration:** \"Let's test in an area where the predictor is *very uncertain*, because there might be a hidden, much better solution we don't know about.\"\n",
    "\n",
    "The function below is called an **Acquisition Function**. The peak of this function shows the most valuable place to test next‚Äîthe spot with the best combination of high predicted performance and high uncertainty.\n",
    "\n",
    "**üëá Interactive Demo:** This chart is linked to the one above. Click on the top chart to add points and watch how the \"Smart Decision Maker\" changes its recommendation for the next best test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:450: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along axis 1; size of axis is 200 but size of corresponding boolean axis is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     91\u001b[39m button.on_click(on_button_click)\n\u001b[32m     92\u001b[39m reset_button.on_click(on_reset_click)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[43mupdate_bo_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_samples_bo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_samples_bo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Initial plot\u001b[39;00m\n\u001b[32m     96\u001b[39m VBox([fig_bo, button, reset_button])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mupdate_bo_plot\u001b[39m\u001b[34m(X, y)\u001b[39m\n\u001b[32m     40\u001b[39m y_pred, sigma = gpr.predict(x_range_bo, return_std=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Calculate Acquisition\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m ei = \u001b[43mexpected_improvement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_range_bo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m next_x = x_range_bo[np.argmax(ei)]\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m fig_bo.batch_update():\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# Clear previous traces\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mexpected_improvement\u001b[39m\u001b[34m(X, X_sample, Y_sample, gpr, xi)\u001b[39m\n\u001b[32m     24\u001b[39m     Z = imp / sigma\n\u001b[32m     25\u001b[39m     ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[43mei\u001b[49m\u001b[43m[\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m]\u001b[49m = \u001b[32m0.0\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ei.ravel()\n",
      "\u001b[31mIndexError\u001b[39m: boolean index did not match indexed array along axis 1; size of axis is 200 but size of corresponding boolean axis is 1"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Let's create a combined, more powerful interactive widget for the whole BO loop\n",
    "\n",
    "# --- SETUP ---\n",
    "x_range_bo = np.linspace(0, 20, 200).reshape(-1, 1)\n",
    "y_true_bo = black_box_function(x_range_bo)\n",
    "\n",
    "X_samples_bo = np.array([[2.0], [18.0]])\n",
    "y_samples_bo = black_box_function(X_samples_bo)\n",
    "\n",
    "kernel_bo = C(1.0, (1e-3, 1e3)) * RBF(5, (1e-2, 1e2))\n",
    "\n",
    "# --- ACQUISITION FUNCTION ---\n",
    "def expected_improvement(X, X_sample, Y_sample, gpr, xi=0.01):\n",
    "    mu, sigma = gpr.predict(X, return_std=True)\n",
    "    mu_sample = gpr.predict(X_sample)\n",
    "\n",
    "    sigma = sigma.reshape(-1, 1)\n",
    "    mu_sample_opt = np.max(mu_sample)\n",
    "\n",
    "    with np.errstate(divide='warn'):\n",
    "        imp = mu - mu_sample_opt - xi\n",
    "        Z = imp / sigma\n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei[sigma == 0.0] = 0.0\n",
    "\n",
    "    return ei.ravel()\n",
    "\n",
    "# --- FIGURE WIDGET ---\n",
    "fig_bo = go.FigureWidget(make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1, \n",
    "                                      subplot_titles=(\"1. The 'Smart Predictor' updates its belief\", \n",
    "                                                    \"2. The 'Smart Decision Maker' suggests the next test\")))\n",
    "\n",
    "# --- PLOT UPDATE LOGIC ---\n",
    "def update_bo_plot(X, y):\n",
    "    # Fit GP\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel_bo, n_restarts_optimizer=10, random_state=0)\n",
    "    gpr.fit(X, y)\n",
    "    y_pred, sigma = gpr.predict(x_range_bo, return_std=True)\n",
    "    \n",
    "    # Calculate Acquisition\n",
    "    ei = expected_improvement(x_range_bo, X, y, gpr)\n",
    "    next_x = x_range_bo[np.argmax(ei)]\n",
    "    \n",
    "    with fig_bo.batch_update():\n",
    "        # Clear previous traces\n",
    "        fig_bo.data = []\n",
    "\n",
    "        # --- Top Plot: GP ---\n",
    "        fig_bo.add_trace(go.Scatter(x=x_range_bo.ravel(), y=y_true_bo.ravel(), mode='lines', line=dict(color='red', dash='dash'), name='True Efficiency (Unknown)'), row=1, col=1)\n",
    "        fig_bo.add_trace(go.Scatter(x=X.ravel(), y=y.ravel(), mode='markers', marker=dict(color='red', size=12, symbol='x'), name='Test Results'), row=1, col=1)\n",
    "        fig_bo.add_trace(go.Scatter(x=x_range_bo.ravel(), y=y_pred + 1.96 * sigma, line=dict(color='rgba(0,100,80,0.2)'), showlegend=False), row=1, col=1)\n",
    "        fig_bo.add_trace(go.Scatter(x=x_range_bo.ravel(), y=y_pred - 1.96 * sigma, line=dict(color='rgba(0,100,80,0.2)'), fill='tonexty', fillcolor='rgba(0,100,80,0.2)', name='Uncertainty'), row=1, col=1)\n",
    "        fig_bo.add_trace(go.Scatter(x=x_range_bo.ravel(), y=y_pred, mode='lines', line=dict(color='green', width=3), name='Predictor Guess'), row=1, col=1)\n",
    "        \n",
    "        # --- Bottom Plot: Acquisition Function ---\n",
    "        fig_bo.add_trace(go.Scatter(x=x_range_bo.ravel(), y=ei, mode='lines', line=dict(color='blue', width=3), name='Next Test Value Score'), row=2, col=1)\n",
    "        fig_bo.add_trace(go.Scatter(x=[next_x], y=[np.max(ei)], mode='markers', marker=dict(color='purple', size=14, symbol='star'), name='Recommended Next Test'), row=2, col=1)\n",
    "        \n",
    "        # --- Layout ---\n",
    "        fig_bo.update_layout(height=600, legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "        fig_bo.update_yaxes(title_text=\"Efficiency Score\", row=1, col=1)\n",
    "        fig_bo.update_yaxes(title_text=\"Value Score\", row=2, col=1)\n",
    "        fig_bo.update_xaxes(title_text=\"Route Configuration Parameter\", row=2, col=1)\n",
    "\n",
    "# --- BUTTON INTERACTION ---\n",
    "from ipywidgets import Button, VBox\n",
    "\n",
    "button = Button(description=\"Run Next Smart Test!\", button_style='success', icon='lightbulb-o')\n",
    "reset_button = Button(description=\"Reset\", button_style='warning', icon='refresh')\n",
    "\n",
    "def on_button_click(b):\n",
    "    global X_samples_bo, y_samples_bo\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel_bo, n_restarts_optimizer=10, random_state=0).fit(X_samples_bo, y_samples_bo)\n",
    "    ei = expected_improvement(x_range_bo, X_samples_bo, y_samples_bo, gpr)\n",
    "    next_x = x_range_bo[np.argmax(ei)]\n",
    "    next_y = black_box_function(next_x)\n",
    "    \n",
    "    X_samples_bo = np.vstack([X_samples_bo, next_x])\n",
    "    y_samples_bo = np.vstack([y_samples_bo, next_y])\n",
    "    \n",
    "    update_bo_plot(X_samples_bo, y_samples_bo)\n",
    "\n",
    "def on_reset_click(b):\n",
    "    global X_samples_bo, y_samples_bo\n",
    "    X_samples_bo = np.array([[2.0], [18.0]])\n",
    "    y_samples_bo = black_box_function(X_samples_bo)\n",
    "    update_bo_plot(X_samples_bo, y_samples_bo)\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "reset_button.on_click(on_reset_click)\n",
    "\n",
    "update_bo_plot(X_samples_bo, y_samples_bo) # Initial plot\n",
    "\n",
    "VBox([fig_bo, button, reset_button])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The Bayesian Optimization Loop: Continuous Improvement (4 minutes)\n",
    "\n",
    "This is where it all comes together. The process is a simple, powerful loop:\n",
    "\n",
    "1.  **Start:** Run a few initial tests to get baseline data.\n",
    "2.  **Predict:** The \"Smart Predictor\" (top graph) models the efficiency landscape based on all current results.\n",
    "3.  **Decide:** The \"Smart Decision Maker\" (bottom graph) identifies the single most valuable place for the next test.\n",
    "4.  **Test:** You run that one test on your real-world system.\n",
    "5.  **Learn & Repeat:** Add the new result to your data, and the loop repeats. The model gets smarter with every cycle.\n",
    "\n",
    "Use the **\"Run Next Smart Test!\"** button in the demo above to step through this loop. Notice how the algorithm first explores uncertain areas and then begins to exploit the most promising region to find the optimal solution much faster than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bayesian Optimization in Logistics: Real-World Impact (2 minutes)\n",
    "BO can provide a significant competitive advantage in logistics by driving efficiency and cost savings. Key applications include:\n",
    "\n",
    "* **ü§ñ Optimising ML Models:** Finding the best settings (hyperparameters) for demand forecasting or delivery time estimation models.\n",
    "\n",
    "* **üöö Route & Network Optimisation:** Fine-tuning the parameters of a vehicle routing algorithm to minimise fuel or reduce delivery times.\n",
    "\n",
    "* **üè≠ Warehouse Robotics:** Developing optimal policies for how robots move and sort items in an automated warehouse by using expensive simulations more effectively.\n",
    "\n",
    "* **‚õìÔ∏è Supply Chain Design:** Finding optimal locations for new distribution centres by balancing costs, lead times, and service levels.\n",
    "\n",
    "* **üì¶ Inventory Management:** Optimising inventory control policies under uncertain demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion & Call to Action (1 minute)\n",
    "\n",
    "* **Key Takeaway:** Bayesian Optimization is an intuitive method for solving expensive, 'black-box' problems. It finds the best solutions faster by combining smart predictions with intelligent decision-making.\n",
    "\n",
    "* **Your Advantage:** Reducing the number of expensive trials provides a significant competitive advantage, driving efficiency, cost savings, and innovation.\n",
    "\n",
    "* **Next Steps:** Think about where your operations face expensive trial-and-error. **Talk to your data science or R&D teams** about exploring Bayesian Optimization for these challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
